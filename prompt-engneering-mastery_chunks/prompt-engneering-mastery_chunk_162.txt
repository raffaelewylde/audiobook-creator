e
the most relevant context to form a response. This practice is typically
referred to as RAG.Retrieval Augmented Generation (RAG)
Vector databases are a key component of RAG, which typically involves
searching by similarity to the query , retrieving the most relevant documents,
and inserting them into the prompt as context. This lets you stay within
what fits in the current context window , while avoiding spending money on
wasted tokens by inserting irrelevant text documents in the context.
Retrieval can also be done using traditional database searches or web
browsing, and in many cases a vector search by semantic similarity is not
necessary . RAG is typically used to solve hallucinations in open-ended
scenarios, like a user talking to a chatbot that is prone to making things up
when asked about something not in its training data. Vector search can
insert documents that are semantically similar to the user query into the
prompt, greatly decreasing the chances the chatbot will hallucinate.
For example, if your author Mike told a chatbot “My name is Mike,” then
three messages later asked, “What is my name?” it can easily recall the
right answer . The message containing Mike’ s name is still within the
context window of the chat. However , if it was 3,000 messages ago, the text
of those messages may be too lar ge to fit inside the context window .
Without this important context, it might hallucinate a name or refuse to
answer for lack of information. A keyword search might help but could
return too many irrelevant documents or fail to recall the right context inwhich the information was captured in the past. There may be many times
Mike mentioned the word name  in dif ferent formats, and for dif ferent
reasons. By passing the question to the vector database, it can return the top
three similar messages from the chat that match what the user asked:
## Context
Most relevant previous user messages:
1. "My name is Mike".
2. "My dog's name is Hercules".
3. "My coworker's n