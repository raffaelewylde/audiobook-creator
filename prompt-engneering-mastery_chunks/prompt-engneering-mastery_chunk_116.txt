MessagePromp
from langchain_openai.chat_models  import ChatOpenAI
prompt=PromptTemplate (
 template ='''You are a helpful assistant that transla {output_language} .''',
 input_variables =["input_language" , "output_language"
)
system_message_prompt  = SystemMessagePromptTemplate (p
chat = ChatOpenAI ()
chat.invoke(system_message_prompt .format_messages (
input_language ="English" ,output_language ="French" ))
Output:
AIMessage (content="Vous êtes un assistant utile qui t
français .", additional_kwargs= {}, example=False)
Output Parsers
In Chapter 3 , you used regular expressions (regex) to extract structured data
from text that contained numerical lists, but it’ s possible to do this
automatically in LangChain with output parsers .
Output parsers  are a higher -level abstraction provided by LangChain for
parsing structured data from LLM string responses. Currently the available
output parsers are:
List parserReturns a list of comma-separated items.
Datetime parser
Parses an LLM output into datetime format.
Enum parser
Parses strings into enum values.
Auto-fixing parser
Wraps another output parser , and if that output parser fails, it will
call another LLM to fix any errors.
Pydantic (JSON) parser
Parses LLM responses into JSON output that conforms to a Pydantic
schema.
Retry parser
Provides retrying a failed parse from a previous output parser .
Structur ed output parser
Can be used when you want to return multiple fields.
XML  parser
Parses LLM responses into an XML-based format.As you’ll discover , there are two important functions for LangChain output
parsers:
.get_format_instructions()
This function provides the necessary instructions into your prompt to
output a structured format that can be parsed.
.parse(llm_output: str)
This function is responsible for parsing your LLM responses into a
predefined format.
Generally , you’ll find that the Pydantic (JSON) parser with
ChatOpenAI()  provides the most flexibility .
The Pydantic (JSON) parser takes advantage of the