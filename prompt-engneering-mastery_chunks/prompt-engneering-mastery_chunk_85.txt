       The number of tokens in the text string.
    Raises:
        ValueError: If the encoding name is not recog
    """
    encoding  = tiktoken .get_encoding (encoding_name )
    num_tokens  = len(encoding .encode(text_string ))
    return num_tokens
# 4. Use the function to count the number of tokens i
text_string  = "Hello world! This is a test."
print(count_tokens (text_string , "cl100k_base" ))
This code outputs 8.
Estimating Token Usage for Chat API
Calls
ChatGPT  models, such as GPT -3.5-turbo and GPT -4, utilize tokens
similarly to previous completion models. However , the message-based
structure makes token counting for conversations more challenging:def num_tokens_from_messages (messages , model="gpt-3.5
    """Return the number of tokens used by a list of 
    try:
        encoding  = tiktoken .encoding_for_model (model)
    except KeyError :
        print("Warning: model not found. Using cl100k
        encoding  = tiktoken .get_encoding ("cl100k_base
    if model in {
        "gpt-3.5-turbo-0613" ,
        "gpt-3.5-turbo-16k-0613" ,
        "gpt-4-0314" ,
        "gpt-4-32k-0314" ,
        "gpt-4-0613" ,
        "gpt-4-32k-0613" ,
        }:
        tokens_per_message  = 3
        tokens_per_name  = 1
    elif model == "gpt-3.5-turbo-0301" :
        tokens_per_message  = 4  # every message follo
        # <|start|>{role/name}\n{content}<|end|>\n
        tokens_per_name  = -1  # if there's a name, th
    elif "gpt-3.5-turbo"  in model:
        print('''Warning: gpt-3.5-turbo may update ov
        num tokens assuming gpt-3.5-turbo-0613.''' )
        return num_tokens_from_messages (messages , mod
    elif "gpt-4" in model:
        print('''Warning: gpt-4 may update over time.
        Returning num tokens assuming gpt-4-0613.''' )        return num_tokens_from_messages (messages , mod
    else:
        raise NotImplementedError (
            f"""num_tokens_from_messages() is not imp
            {model}."""
        )
    num_tokens  = 0
    for message in 