e is far away because it is rarely associated with the
word mouse  in the training data. The word ship is still colocated near the
other forms of transport but is closer to mouse  and rat  because they are
often found on ships, as per the training data.Figure 5-2. Multidimensional vector distances
A vector database stores the text records with their vector representation as
the key . This is unlike other types of databases, where you might find
records based on an ID, relation, or where the text contains a string. For
example, if you queried a relational database based on the text in Figure 5-2
to find records where text contains mouse , you’d return the record
mickey mouse  but nothing else, as no other record contains that exact
phrase. With vectors search you could also return the records cheese  and
trap , because they are closely associated, even though they aren’ t an
exact match for your query .The ability to query based on similarity is extremely useful, and vector
search powers a lot of AI functionality . For example:
Document r eading
Find related sections of text to read in order to provide a more
accurate answer .
Recommendation systems
Discover similar products or items in order to suggest them to a user .
Long-term memory
Look up relevant snippets of conversation history so a chatbot
remembers past interactions.
AI models are able to handle these tasks at small scale, as long as your
documents, product list, or conversation memory fits within the token limits
of the model you’re using. However , at scale you quite quickly run into
token limits and excess cost from passing too many tokens in each prompt.
OpenAI’ s gpt-4-1106-preview  was released in November 2023  with
an enormous 128,000 token context window , but it costs 10 times more per
token than gpt-3.5-turbo , which has 88% fewer tokens and was
released a year earlier . The more ef ficient approach is to look up only the
most relevant records to pass into the prompt at runtime in order to provid