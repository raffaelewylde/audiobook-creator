u need.
CharacterTextSplitter  and load_summarize_chain  are from
the LangChain package and will help with text processing, while Pandas
(imported as pd) will help manipulate your data.
Next, you’ll be dealing with your data:
df = pd.DataFrame (generated_scenes )
Here, you create a Pandas DataFrame from the generated_scenes
variable, ef fectively converting your raw scenes into a tabular data format
that Pandas can easily manipulate.
Then you need to consolidate your text:
all_character_script_text  = "\n".join(df.character_sc
In this line, you’re transforming the character_script  column from
your DataFrame into a single text string. Each entry in the column is
converted into a list item, and all items are joined together with new lines in
between, resulting in a single string that contains all character scripts.
Once you have your text ready , you prepare it for the summarization
process:text_splitter  = CharacterTextSplitter .from_tiktoken_e
    chunk_size =1500, chunk_overlap =200
)
docs = text_splitter .create_documents ([all_character_
Here, you create a CharacterTextSplitter  instance using its class
method from_tiktoken_encoder , with specific parameters for chunk
size and overlap. You then use this text splitter to split your consolidated
script text into chunks suitable for processing by your summarization tool.
Next, you set up your summarization tool:
chain = load_summarize_chain (llm=model, chain_type ="m
This line is about setting up your summarization process. You’re calling a
function that loads a summarization chain with a chat model in a map-
reduce  style approach.
Then you run the summarization:
summary = chain.invoke(docs)
This is where you actually perform the text summarization. The invoke
method executes the summarization on the chunks of text you preparedearlier and stores the summary into a variable.
Finally , you print the result:
print(summary['output_text' ])
This is the culmination of all your hard work. The resulting summary text is
pr