nt(result)
Output:
[Article(points='The growing interest in AI in variou
contrarian_points ='Without stringent regulations, ...
author='Dr. Jane Smith' )]
You’ll start by importing various modules, including
PydanticToolsParser  and ChatPromptTemplate , essential for
parsing and templating your prompts. Then, you’ll define a Pydantic model,
Article , to specify the structure of the information you want to extract
from a given text. With the use of a custom prompt template and the
ChatOpenAI model, you’ll instruct the AI to extract key points and
contrarian views from an article. Finally , the extracted data is neatly
converted into your predefined Pydantic model and printed out, allowing
you to see the structured information pulled from the text.
There are several key points, including:
Converting Pydantic schema to OpenAI toolstools = [convert_to_openai_tool(p) for p in
pydantic_schemas]
Binding the tools dir ectly to the LLM
model = model.bind_tools(tools=tools)
Creating an LCEL  chain that contains a tools parser
chain = prompt | model |
PydanticToolsParser(tools=pydantic_schemas)
Extracting Data with LangChain
The create_extraction_chain_pydantic  function provides a more
concise version of the previous implementation. By simply inserting a
Pydantic model and an LLM that supports function calling, you can easily
achieve parallel function calling.
Input:
from langchain.chains.openai_tools  import create_extr
from langchain_openai.chat_models  import ChatOpenAI
from langchain_core.pydantic_v1  import BaseModel , Fie
# Make sure to use a recent model that supports tools
model = ChatOpenAI (model="gpt-3.5-turbo-1106" )class Person(BaseModel ):
    """A person's name and age."""
    name: str = Field(..., description ="The person's 
    age: int = Field(..., description ="The person's a
chain = create_extraction_chain_pydantic (Person, mode
chain.invoke({'input':'''Bob is 25 years old. He live
He likes to play basketball. Sarah is 30 years old. S
Francisco. She likes