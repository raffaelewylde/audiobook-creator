s and documents.
Remember to install tiktoken and langchain-text-splitters with pip
install tiktoken langchain-text-splitters .
To split by token count in LangChain, you can use a
CharacterTextSplitter  with a .from_tiktoken_encoder()
function.
You’ll initially create a CharacterTextSplitter  with a chunk size of
50 characters and no overlap. Using the split_text  method, you’rechopping the text into pieces and then printing out the total number of
chunks created.
Then you’ll do the same thing, but this time with a chunk overlap  of 48
characters. This shows how the number of chunks changes based on
whether you allow overlap , illustrating the impact of these settings on how
your text gets divided:
from langchain_text_splitters  import CharacterTextSpl
text = """
Biology is a fascinating and diverse field of science
living world and its intricacies \n\n. It encompasses
origins, diversity, structure, function, and interact
from molecules and cells to organisms and ecosystems 
essay, we will delve into the core concepts of biolog
areas of study, and its significance in shaping our u
natural world. \n\n ...(truncated to save space)...
"""
# No chunk overlap:
text_splitter  = CharacterTextSplitter .from_tiktoken_e
chunk_size =50, chunk_overlap =0, separator ="\n",
)
texts = text_splitter .split_text (text)
print(f"Number of texts with no chunk overlap: {len(t
# Including a chunk overlap:text_splitter  = CharacterTextSplitter .from_tiktoken_e
chunk_size =50, chunk_overlap =48, separator ="\n",
)
texts = text_splitter .split_text (text)
print(f"Number of texts with chunk overlap: {len(text
Output:
Number of texts with no chunk overlap: 3
Number of texts with chunk overlap: 6
In the previous section, you used the following to load and split the .pdf into
LangChain documents:
pages = loader.load_and_split()
It’s possible for you to have more granular control on the size of each
document by creating a TextSplitter  and attaching it to your
Document  loading pipelines:
def lo