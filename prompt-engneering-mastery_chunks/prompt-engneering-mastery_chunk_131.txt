-02 at 15:
From this example, it’ s clear how you can ef fectively manage multiple
function calls. You’ve seen how the schedule_meeting  function was
called twice in a row to arrange dif ferent meetings. This demonstrates howflexibly and ef fortlessly you can handle varied and complex requests using
AI-powered tools.
Function Calling in LangChain
If you’d prefer to avoid writing JSON schema and simply want to extract
structured data from an LLM response, then LangChain allows you to use
function calling with Pydantic.
Input:
from langchain.output_parsers.openai_tools  import Pyd
from langchain_core.utils.function_calling  import con
from langchain_core.prompts  import ChatPromptTemplate
from langchain_openai.chat_models  import ChatOpenAI
from langchain_core.pydantic_v1  import BaseModel , Fie
from typing import Optional
class Article(BaseModel ):
    """Identifying key points and contrarian views in
    points: str = Field(..., description ="Key points 
    contrarian_points : Optional [str] = Field(
        None, description ="Any contrarian points ackn
    )
    author: Optional [str] = Field(None, description ="_EXTRACTION_TEMPLATE  = """Extract and save the releva
in the following passage together with their properti
If a property is not present and is not required in t
do not include it in the output."""
# Create a prompt telling the LLM to extract informat
prompt = ChatPromptTemplate .from_messages (
    {("system" , _EXTRACTION_TEMPLATE ), ("user", "{inp
)
model = ChatOpenAI ()
pydantic_schemas  = [Article]
# Convert Pydantic objects to the appropriate schema:
tools = [convert_to_openai_tool (p) for p in pydantic_
# Give the model access to these tools:
model = model.bind_tools (tools=tools)
# Create an end to end chain:
chain = prompt | model | PydanticToolsParser (tools=py
result = chain.invoke(
    {
        "input": """In the recent article titled 'AI         key points addressed include the growing inte
        author, Dr. Jane Smith, ..."""
    }
)
pri