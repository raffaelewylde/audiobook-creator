 from the API.
7. texts  is a list of strings from your database.
8. output  is assigned the result of calling the query()  function with
the texts  list.
9. The output  variable is printed, which will display the feature
embeddings for the input texts.
When you run this code, the script will send text to the Hugging Face API,
and the API will return embeddings for each string of text sent.
If you pass the same text into an embedding model, youâ€™ll get the same
vector back every time. However , vectors are not usually comparable across
models (or versions of models) due to dif ferences in training. The
embeddings you get from OpenAI are dif ferent from those you get from
BER T or spaCy (a natural language processing library).
The main dif ference with embeddings generated by modern transformer
models is that the vectors are contextual rather than static, meaning the
word bank  would have dif ferent embeddings in the context of a riverbank
versus financial bank . The embeddings you get from OpenAI Ada 002 and
HuggingFace Sentence Transformers are examples of dense vectors, whereeach number in the array is almost always nonzero (i.e., they contain
semantic information). There are also sparse vectors , which normally have a
large number of dimensions (e.g., 100,000+) with many of the dimensions
having a value of zero. This allows capturing specific important features
(each feature can have its own dimension), which tends to be important for
performance in keyword-based search applications. Most AI applications
use dense vectors for retrieval, although hybrid search (both dense and
sparse vectors) is rising in popularity , as both similarity and keyword search
can be useful in combination.
The accuracy of the vectors is wholly reliant on the accuracy of the model
you use to generate the embeddings. Whatever biases or knowledge gaps
the underlying models have will also be an issue for vector search. For
example, the text-embedding-ada-002  model is currently only
trained 