 message types are AIMessage , HumanMessage , and
SystemMessage . The output from a chat model will always be an
AIMessage .
SystemMessage
Represents information that should be instructions to the AI system.
These are used to guide the AI’s behavior or actions in some way .
HumanMessage
Represents information coming from a human interacting with the AI
system. This could be a question, a command, or any other input
from a human user that the AI needs to process and respond to.AIMessage
Represents information coming from the AI system itself. This is
typically the AI’s response to a HumanMessage  or the result of a
SystemMessage  instruction.
NOTE
Make sure to leverage the SystemMessage  for delivering explicit directions. OpenAI has refined
GPT-4 and upcoming LLM models to pay particular attention to the guidelines given within this type
of message.
Let’s create a joke generator in LangChain.
Input:
from langchain_openai.chat_models  import ChatOpenAI
from langchain.schema  import AIMessage , HumanMessage ,
chat = ChatOpenAI (temperature =0.5)
messages  = [SystemMessage (content='''Act as a senior 
at a startup company.''' ),
HumanMessage (content='''Please can you provide a funn
about software engineers?''' )]
response  = chat.invoke(input=messages )
print(response .content)Output:
Sure, here's a lighthearted joke for you:
Why did the software  engineer  go broke?
Because he lost his domain in a bet and couldn't affo
First, you’ll import ChatOpenAI , AIMessage , HumanMessage , and
SystemMessage . Then create an instance of the ChatOpenAI  class
with a temperature parameter of 0.5 (randomness).
After creating a model, a list named messages  is populated with a
SystemMessage  object, defining the role for the LLM, and a
HumanMessage  object, which asks for a software engineer—related joke.
Calling the chat model with .invoke(input=messages)  feeds the
LLM with a list of messages, and then you retrieve the LLM’ s response
with response.content .
There is a legacy meth